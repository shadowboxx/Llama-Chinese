

# CUDA_VISIBLE_DEVICES=0 python inference-speed/GPU/vllm_example/api_server.py --port 8000 --model "/mnt/d/LLM/models/Meta/Llama3-Chinese" 

python3 scripts/api/accelerate_client.py 